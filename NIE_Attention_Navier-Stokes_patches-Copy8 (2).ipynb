{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd9c69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#General libraries\n",
    "import os, argparse\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Torch libraries\n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "#Custom libraries\n",
    "from utils import Train_val_split, Dynamics_Dataset, Test_Dynamics_Dataset\n",
    "from utils import fix_random_seeds,to_np\n",
    "import IE_source.kernels as kernels\n",
    "from IE_source.experiments import Full_experiment_AttentionalIE_PDE, Full_experiment_AttentionalIE_PDE_Navier_Stokes\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from IE_source.kernels import model_blocks\n",
    "\n",
    "from IE_source.Attentional_IE_solver import masking_function, Integral_attention_solver\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"\n",
    "    \n",
    "\n",
    "parser = argparse.ArgumentParser(description='Neural IE')\n",
    "parser.add_argument('-root_path', metavar='DIR', default='',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('-dataset-name', default='stl10',\n",
    "                    help='dataset name', choices=['acrobot_dataset'])\n",
    "\n",
    "parser.add_argument('-j', '--workers', default=12, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 32)')\n",
    "parser.add_argument('--epochs', default=3000, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('-b', '--batch_size', default=20, type=int,\n",
    "                    metavar='N',\n",
    "                    help='mini-batch size (default: 256), this is the total '\n",
    "                         'batch size of all GPUs on the current node when '\n",
    "                         'using Data Parallel or Distributed Data Parallel')\n",
    "parser.add_argument('--lr', '--learning-rate', default=1e-4, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "parser.add_argument('--seed', default=None, type=int,\n",
    "                    help='seed for initializing training. ')\n",
    "parser.add_argument('--disable-cuda', action='store_true',\n",
    "                    help='Disable CUDA')\n",
    "parser.add_argument('--fp16-precision', action='store_true',\n",
    "                    help='Whether or not to use 16-bit precision GPU training.')\n",
    "\n",
    "parser.add_argument('--out_dim', default=128, type=int,\n",
    "                    help='feature dimension (default: 128)')\n",
    "parser.add_argument('--log-every-n-steps', default=100, type=int,\n",
    "                    help='Log every n steps')\n",
    "parser.add_argument('--temperature', default=0.07, type=float,\n",
    "                    help='softmax temperature (default: 0.07)')\n",
    "parser.add_argument('--n-views', default=2, type=int, metavar='N',\n",
    "                    help='Number of views for contrastive learning training.')\n",
    "parser.add_argument('--gpu-index', default=0, type=int, help='Gpu index.')\n",
    "parser.add_argument('--model', default='simclr', choices=['simclr','lipschitz_simclr','vae','gan'], \n",
    "                    help='Models to be used')\n",
    "parser.add_argument('--mode', default='train', choices=['train','evaluate'], \n",
    "                    help='Set to ''evaluate'' if inference is desired')\n",
    "parser.add_argument('--training_split', default=0.25,type=float, \n",
    "                    help='Fraction of the samples that will be used for validation')\n",
    "parser.add_argument('--resume_from_checkpoint', default=None, \n",
    "                    help='Give string to run number. Ex: \"run12\"')\n",
    "parser.add_argument('--plot_freq', default=1, type=int,help='')\n",
    "parser.add_argument('--experiment_name', default=None,help='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42f81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "args.mode='train' to train the model, and args.mode='evaluate' for testing.\n",
    "args.resume_from_checkpoint='run#' allows to load the model used for run#\n",
    "to resume training or for testing it.\n",
    "'''\n",
    "args = parser.parse_args(\"\")\n",
    "args.model='nie'\n",
    "args.mode='train'\n",
    "args.mode = 'evaluate'\n",
    "args.dataset_name = 'integral_equations'\n",
    "args.seed = 7\n",
    "args.experiment_name = 'Navier-Stokes_patch-8'\n",
    "args.plot_freq = 10\n",
    "args.device = device\n",
    "args.num_dim_plot = 2\n",
    "args.lr = 1e-4\n",
    "args.min_lr=1e-9\n",
    "args.T_max = 101\n",
    "args.plat_patience = 10\n",
    "args.factor = 0.5\n",
    "#args.lr_scheduler = 'ReduceLROnPlateau'\n",
    "args.lr_scheduler = 'CosineAnnealingLR'\n",
    "args.resume_from_checkpoint = 'run146'\n",
    "fix_random_seeds(args.seed)\n",
    "args.perturbation_to_obs0=None\n",
    "args.training_split=0.2\n",
    "args.smoothing_factor=.5\n",
    "args.patience_stopping = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.kernel_split = True\n",
    "args.free_func_nn = False\n",
    "args.kernel_type_nn = True\n",
    "args.G_NN = True\n",
    "args.num_internal_points = 100 \n",
    "args.plot_F_func = False\n",
    "args.f_nn = False\n",
    "args.max_iterations=3\n",
    "args.sampling_points=100 \n",
    "args.time_points= 10  \n",
    "args.support_tensors=False\n",
    "args.support_test=False \n",
    "args.test_points=40  \n",
    "args.combine_points=False\n",
    "args.patches=True\n",
    "args.initialization=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153cded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc59100",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.n_batch=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8570368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.mode=='train':\n",
    "    args.initial_t=True\n",
    "else:\n",
    "    args.initial_t=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5195c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Architecture of the transformer used for quadrature of the integrals.\n",
    "'''\n",
    "args.dim = 32\n",
    "args.dim_emb=64\n",
    "args.n_head=4\n",
    "args.n_blocks=4\n",
    "args.n_ff=128\n",
    "args.attention_type='galerkin'\n",
    "args.final_block=False\n",
    "args.dim_out= args.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b4ce97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6534d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087195f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75727d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09474659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b61bfa",
   "metadata": {},
   "source": [
    "# Burgers dataset has shape explained in https://github.com/zongyi-li/fourier_neural_operator. 1k samples for grid with size of 8192."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197f47cb",
   "metadata": {},
   "source": [
    "# Navier-Stokes dataset same link as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f084f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Eqn_type = 'Navier-Stokes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639afc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Eqn_type == 'Burgers':\n",
    "    Data = spio.loadmat('burgers_data_R10.mat', squeeze_me=True)\n",
    "else:\n",
    "    Data = mat73.loadmat('Navier_Stokes_Dataset/Navier_Stokes_Dataset.mat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef6815",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['a'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Eqn_type == 'Burgers':\n",
    "    Data['a_smooth'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a90a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Eqn_type == 'Burgers':\n",
    "    Data['a_smooth_x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['u'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4b775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a2f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f874958",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_u = torch.from_numpy(Data['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c81761",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_a = torch.from_numpy(Data['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a18e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f11b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This creates the grid for the images.\n",
    "'''\n",
    "t_max = 1 \n",
    "t_min = 0\n",
    "n_points = 64\n",
    "\n",
    "index_np = np.arange(0, n_points, 1, dtype=int)\n",
    "index_np = np.hstack(index_np[:, None])\n",
    "times_np = np.linspace(t_min, t_max, num=n_points)\n",
    "times_np = np.hstack([times_np[:, None]])\n",
    "\n",
    "\n",
    "###########################################################\n",
    "times = torch.from_numpy(times_np[:, :, None]).to(device)\n",
    "times = times.flatten().float()\n",
    "\n",
    "###########################################################\n",
    "args.time_interval=t_min, t_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf3c7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0128484b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac34c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Eqn_type == 'Navier-Stokes':\n",
    "    Data_u = torch.cat([Data_a.unsqueeze(-1),Data_u],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot some of the data to visualize it\n",
    "if Eqn_type == 'Burgers':\n",
    "    for i in range(10):\n",
    "        plt.plot(torch.linspace(0,1,8192),Data_a[i,:])\n",
    "        plt.plot(torch.linspace(0,1,8192),Data_u[i,:])\n",
    "else:\n",
    "    for i in range(5):\n",
    "        plt.plot(torch.linspace(0,1,Data_u.shape[-1]),Data_u[i,17,17,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcubicspline import(natural_cubic_spline_coeffs, \n",
    "                             NaturalCubicSpline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23107662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af5c317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59639310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02474c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Split the data here between train and test.\n",
    "'''\n",
    "if Eqn_type == 'Burgers':\n",
    "    for i in range(1000):\n",
    "        Data_i0 = Data_a[i:i+1,:].unsqueeze(-1)\n",
    "        Data_i1 = Data_u[i:i+1,:].unsqueeze(-1)\n",
    "        if i == 0:\n",
    "            Data = torch.cat([Data_i0,Data_i1],-1)\n",
    "        else:\n",
    "            Data = torch.cat([Data,torch.cat([Data_i0,Data_i1],-1)])\n",
    "        \n",
    "    \n",
    "else:\n",
    "    if args.mode=='train':\n",
    "        Data = Data_u[:-1000,:,:,:]\n",
    "    else:\n",
    "        Data = Data_u[-1000:,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4ea0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d02b020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2351369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5953e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571fe71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data = Data.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8d7bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e03eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.tile(np.linspace(0,Data.shape[1]-1,num=n_points, dtype=np.int64),(Data.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d231a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bec973",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ids = np.tile(np.linspace(0,Data.shape[-1]-1,num=args.time_points, dtype=np.int64),(Data.shape[-1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae7056",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf53bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e6222b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9329b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Integration interval.\n",
    "'''\n",
    "ts_integration = torch.linspace(0,1,Data.shape[-1])\n",
    "ts_integration = ts_integration[t_ids[0]]\n",
    "print(ts_integration)\n",
    "args.ts_integration = ts_integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44f8bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1a5c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Downsample time points and spatial resolution.\n",
    "'''\n",
    "if Eqn_type=='Burgers':\n",
    "    Data = Data[:,ids[0],:]\n",
    "else:\n",
    "    Data = Data[:,ids[0],:,:]\n",
    "    Data = Data[:,:,ids[0],:]\n",
    "    Data = Data[:,:,:,t_ids[0]]\n",
    "    #Data = Data[:,:,:,:args.time_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da81cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883a616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.range_imshow = np.array([np.quantile(to_np(Data).flatten(), 0.15), np.quantile(to_np(Data).flatten(), 0.85)])#np.array([-0.25,0.05])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a60fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.range_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initialize model and dataset.\n",
    "'''\n",
    "n_steps = 100#5000 \n",
    "print('Data.shape: ',Data.shape)\n",
    "\n",
    "\n",
    "Data_splitting_indices = Train_val_split(np.copy(index_np),0)\n",
    "Train_Data_indices = Data_splitting_indices.train_IDs()\n",
    "Val_Data_indices = Data_splitting_indices.val_IDs()\n",
    "print('\\nlen(Train_Data_indices): ',len(Train_Data_indices))\n",
    "print('Train_Data_indices: ',Train_Data_indices)\n",
    "print('\\nlen(Val_Data_indices): ',len(Val_Data_indices))\n",
    "print('Val_Data_indices: ',Val_Data_indices)\n",
    "Dataset = Dynamics_Dataset(Data,times)\n",
    "\n",
    "Dataset_all = Test_Dynamics_Dataset(Data,times)\n",
    "\n",
    "# For the sampler\n",
    "train_sampler = SubsetRandomSampler(Train_Data_indices)\n",
    "valid_sampler = SubsetRandomSampler(Val_Data_indices)\n",
    "    \n",
    "\n",
    "dataloaders = {'train': torch.utils.data.DataLoader(Dataset, sampler=train_sampler, batch_size = args.batch_size, drop_last=True),\n",
    "               'val': torch.utils.data.DataLoader(Dataset, sampler=valid_sampler, batch_size = args.batch_size, drop_last=True),\n",
    "               'test': torch.utils.data.DataLoader(Dataset_all, batch_size = len(np.copy(index_np))),\n",
    "              }\n",
    "\n",
    "model = model_blocks(args.dim+2,\n",
    "                     args.dim_emb,\n",
    "                     args.n_head,\n",
    "                     args.n_blocks,\n",
    "                     args.n_ff,\n",
    "                     args.attention_type,\n",
    "                     args.dim_out,\n",
    "                     args.final_block,\n",
    "                     dropout=0.1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a1fc7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b7aa27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec9665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_mode = 'Fredholm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e4f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fredholm mode\n",
    "mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c6954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volterra mode\n",
    "if exp_mode == 'Volterra':\n",
    "    masking_map =  masking_function(lambda x: 0.,lambda x: x,n_batch=1)\n",
    "    mask_times = times\n",
    "    mask = masking_map.create_mask(mask_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e30e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b3743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a15a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.n_patch = 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4042925f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a57652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67eefde",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initialize encoder for the latent space for the patches.\n",
    "'''\n",
    "Encoder = kernels.SingleConvNeuralNet(\n",
    "    1,\n",
    "    args.dim,\n",
    "    args.dim,\n",
    "    K=[4,4],\n",
    "    S=[4,4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb83ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    Encoder = Encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb84312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.shapes = Encoder(Data[:4,...,:1].permute(0,3,1,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324a249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.n_points= args.shapes[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e5bf28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f5217f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee73a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initialize decoder to go back in original space.\n",
    "'''\n",
    "Decoder = kernels.Decoder_NN_2D(args.shapes[-2]*args.shapes[-1]*args.dim,64**2,[64,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96e4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    Decoder = Decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a22acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40159078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c71c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epochs= 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcaa0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.eqn_type = Eqn_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d17e59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Run experiment here. Train if args.mode='train', test if args.mode='evaluation'.\n",
    "'''\n",
    "Full_experiment_AttentionalIE_PDE_Navier_Stokes(model,Encoder,Decoder,Data, times, index_np, mask, times, args, extrapolation_points=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1184be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b9d7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a64a34e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
