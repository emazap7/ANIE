{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd9c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/dijk/ahf38/conda_envs/neural_ide3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#General libraries\n",
    "import os, argparse\n",
    "import pickle\n",
    "#from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "#Torch libraries\n",
    "import torch \n",
    "\n",
    "#Custom libraries\n",
    "#from load_datasets import load_dataset, create_dataloaders\n",
    "from IE_source.utils import Train_val_split2, Train_val_split3, Dynamics_Dataset2, Test_Dynamics_Dataset\n",
    "from IE_source.utils import fix_random_seeds,to_np, count_parameters\n",
    "#from source.ide_func import NNIDEF, NeuralIDE\n",
    "#from IE_source.solver import IESolver_monoidal\n",
    "import IE_source.kernels as kernels\n",
    "from IE_source.experiments import Full_experiment_AttentionalIE_GeneratedFMRI\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from IE_source.kernels import model_blocks\n",
    "\n",
    "from IE_source.Attentional_IE_solver import masking_function\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"\n",
    "    \n",
    "\n",
    "parser = argparse.ArgumentParser(description='Neural IE')\n",
    "parser.add_argument('-root_path', metavar='DIR', default='/home/ahf38/project/ANIE/',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('-dataset-name', default='stl10',\n",
    "                    help='dataset name', choices=['acrobot_dataset'])\n",
    "parser.add_argument('-j', '--num_workers', default=0, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 32)')\n",
    "parser.add_argument('--epochs', default=3000, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('-b', '--batch_size', default=20, type=int,\n",
    "                    metavar='N',\n",
    "                    help='mini-batch size (default: 256), this is the total '\n",
    "                         'batch size of all GPUs on the current node when '\n",
    "                         'using Data Parallel or Distributed Data Parallel')\n",
    "parser.add_argument('--lr', '--learning-rate', default=1e-4, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "parser.add_argument('--seed', default=None, type=int,\n",
    "                    help='seed for initializing training. ')\n",
    "parser.add_argument('--disable-cuda', action='store_true',\n",
    "                    help='Disable CUDA')\n",
    "parser.add_argument('--fp16-precision', action='store_true',\n",
    "                    help='Whether or not to use 16-bit precision GPU training.')\n",
    "\n",
    "parser.add_argument('--out_dim', default=128, type=int,\n",
    "                    help='feature dimension (default: 128)')\n",
    "parser.add_argument('--log-every-n-steps', default=100, type=int,\n",
    "                    help='Log every n steps')\n",
    "parser.add_argument('--temperature', default=0.07, type=float,\n",
    "                    help='softmax temperature (default: 0.07)')\n",
    "parser.add_argument('--n-views', default=2, type=int, metavar='N',\n",
    "                    help='Number of views for contrastive learning training.')\n",
    "parser.add_argument('--gpu-index', default=0, type=int, help='Gpu index.')\n",
    "parser.add_argument('--model', default='simclr', choices=['simclr','lipschitz_simclr','vae','gan'], \n",
    "                    help='Models to be used')\n",
    "parser.add_argument('--mode', default='train', choices=['train','evaluate'], \n",
    "                    help='Set to ''evaluate'' if inference is desired')\n",
    "parser.add_argument('--validation_split', default=0.25,type=float, \n",
    "                    help='Fraction of the samples that will be used for validation')\n",
    "parser.add_argument('--resume_from_checkpoint', default=None, \n",
    "                    help='Give string to run number. Ex: \"run12\"')\n",
    "parser.add_argument('--plot_freq', default=1, type=int,help='')\n",
    "parser.add_argument('--experiment_name', default=None,help='')\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42f81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model='nie'\n",
    "args.mode='train'\n",
    "#args.mode = 'evaluate'\n",
    "args.dataset_name = 'integral_equations'\n",
    "args.seed = 1\n",
    "fix_random_seeds(args.seed)\n",
    "args.batch_size = 32\n",
    "args.log_per_minibatch=True\n",
    "args.num_minibatches=5\n",
    "args.experiment_name = ''\n",
    "args.plot_freq = 1\n",
    "args.device = device\n",
    "args.num_dim_plot = 20\n",
    "args.lr = 1e-3\n",
    "args.min_lr=1e-6\n",
    "args.T_max = 50\n",
    "args.plat_patience = 10\n",
    "args.factor = 0.5\n",
    "args.warm_up=15\n",
    "args.exp_mode = 'Fredholm' #'Fredholm'\n",
    "# args.temperature=0.001\n",
    "#args.lr_scheduler = 'ReduceLROnPlateau'\n",
    "args.experiment_name = 'GeneratedFMRI' #'Data_RandProj_20pcs_150frames', Data_20pcs_150frames\n",
    "args.data_dim = 'orig' #'Data_2D', 'Data_10D', 'Data_50D', 'Data_orig'\n",
    "args.lr_scheduler = 'CosineAnnealingLR' #'ReduceLROnPlateau'\n",
    "# args.resume_from_checkpoint = 'run20'\n",
    "args.perturbation_to_obs0=None\n",
    "args.downsample_orig_data=10 # Factor by which we will downsampled the original data \n",
    "args.use_first_n_frames = 5000\n",
    "# args.subtract_mean_per_dim = True\n",
    "args.segment_len=20\n",
    "args.validation_split=0.5\n",
    "args.segment_window_factor = 0\n",
    "args.randomly_drop_n_last_frames = None\n",
    "args.drop_n_last_frames=None\n",
    "args.perturbation_to_obs = False\n",
    "args.perturbation_to_t = False\n",
    "args.random_sample_n_points=None\n",
    "# args.perturbation_to_obs_factor = 10000 #This scales the std of the data, like (std_data)/factor. The previous test used factor=20\n",
    "\n",
    "\n",
    "args.kernel_split = True\n",
    "args.free_func_nn = False\n",
    "args.kernel_type_nn = True\n",
    "args.G_NN = True\n",
    "args.num_internal_points = 100 ##For non-attentional model\n",
    "args.plot_F_func = False\n",
    "args.f_nn = False\n",
    "args.max_iterations=3\n",
    "args.sampling_points=100 ##For attentional model\n",
    "args.time_points=100  ##Number of dummy points when support_tensors is True\n",
    "\n",
    "# These options only work with batch_size=1\n",
    "args.support_tensors=False # Dummy points for training\n",
    "args.support_test = False # Plotting for inference\n",
    "args.combine_points=False\n",
    "args.output_support_tensors = False # Set it to false to return just the real coordinates\n",
    "args.use_support = False\n",
    "\n",
    "args.integral_c='cte_2nd_half' #to pass c as a function fitted on few real points defined by 'num_points_for_c' or None \n",
    "args.num_points_for_c=1\n",
    "args.c_scaling_factor=1\n",
    "\n",
    "args.compute_loss_on_unseen_points = False\n",
    "args.smoothing_factor=0.5\n",
    "args.one_curve_per_frame=True\n",
    "\n",
    "args.dim = 80\n",
    "args.dim_emb=128\n",
    "args.n_head=4\n",
    "args.n_blocks=3\n",
    "args.n_ff=128\n",
    "args.attention_type='galerkin'\n",
    "args.final_block=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1365cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = 1 #frames.shape[0]\n",
    "t_min = 0\n",
    "n_points = 100 #This is for the data\n",
    "\n",
    "index_np = np.arange(0, n_points, 1, dtype=int)\n",
    "index_np = np.hstack(index_np[:, None])\n",
    "times_np = np.linspace(t_min, t_max, num=n_points)\n",
    "times_np = np.hstack([times_np[:, None]])\n",
    "# print('times_np: ',times_np)\n",
    "\n",
    "###########################################################\n",
    "times = torch.from_numpy(times_np[:, :, None]).to(device)\n",
    "times = times.flatten().float()\n",
    "# print('times :',times)\n",
    "###########################################################\n",
    "args.time_interval=t_min, t_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087195f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_blocks(args.dim,\n",
    "                     args.dim_emb,\n",
    "                     args.n_head,\n",
    "                     args.n_blocks,\n",
    "                     args.n_ff,\n",
    "                     args.attention_type,\n",
    "                     args.final_block,\n",
    "                     dropout=0.1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    \n",
    "print('Total: ',count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639afc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "# Data = pickle.load(open( \"30_IE_Spirals_noise.pkl\", \"rb\" )) # Emanuele's data \n",
    "print('Loading ',os.path.join(\"./datasets\",args.experiment_name + \".p\"))\n",
    "Data_dict = pickle.load(open(os.path.join(\"./datasets\",args.experiment_name + \".p\"), \"rb\" )) #This data was saved in GPU. So transform it to CPU first\n",
    "print(Data_dict.keys())\n",
    "Data = Data_dict['Data_'+args.data_dim]#[:50,:]\n",
    "print('[imported] Data.shape: ',Data.shape)\n",
    "\n",
    "if args.data_dim=='orig':\n",
    "    # from sklearn.preprocessing import StandardScaler\n",
    "    # args.scaling_factor = StandardScaler()\n",
    "     # from sklearn.preprocessing import StandardScaler\n",
    "    # args.scaling_factor = StandardScaler()\n",
    "    import matplotlib.pyplot as plt\n",
    "    Data = np.log(Data.values)\n",
    "    args.scaling_factor = np.quantile(np.abs(Data),0.90)\n",
    "    Data = (Data-np.mean(Data))/args.scaling_factor\n",
    "    Data = Data[::args.downsample_orig_data,:]\n",
    "else: \n",
    "    args.scaling_factor = np.quantile(np.abs(Data),0.90)\n",
    "\n",
    "print('Data.shape: ',Data.shape)\n",
    "args.std_noise = np.mean(np.std(Data,axis=1))/args.perturbation_to_obs_factor if args.perturbation_to_obs else 0\n",
    "print('scaling_factor: ',args.scaling_factor)\n",
    "\n",
    "\n",
    "# args.range_imshow = np.array([np.quantile(Data.flatten(), 0.4), np.quantile(Data.flatten(), 0.55)])#np.array([-0.25,0.05]) #\n",
    "# print('args.range_imshow: ',args.range_imshow)\n",
    "# args.fitted_pca = Data_dict['pca']\n",
    "# Data = to_np(Data[:,:4]) #This might be necessary in some cases. Not sure why some of these variables were saved as CUDA.\n",
    "\n",
    "train_val = 20000 # Number of frames for train and validation. The remaining will be for test\n",
    "n_steps = 3000 #number of iterations for training. default=3k epochs\n",
    "# segment_len = args.segment_len\n",
    "\n",
    "# Data_test = Data[train_val:,:]\n",
    "Data = Data[:args.use_first_n_frames,:] #Data[:train_val,:]\n",
    "\n",
    "n_points = Data.shape[0]\n",
    "extrapolation_points = Data.shape[0]\n",
    "\n",
    "t_max = 1 #frames.shape[0]\n",
    "t_min = 0\n",
    "\n",
    "index_np = np.arange(0, n_points, 1, dtype=int)\n",
    "index_np = np.hstack(index_np[:, None])\n",
    "# times_np = np.linspace(t_min, t_max, num=n_points) #Original\n",
    "times_np = np.linspace(t_min, t_max, num=args.segment_len)\n",
    "times_np = np.hstack([times_np[:, None]])\n",
    "# print('times_np: ',times_np)\n",
    "\n",
    "###########################################################\n",
    "times = torch.from_numpy(times_np[:, :, None])#.to(args.device)\n",
    "times = times.flatten()\n",
    "\n",
    "\n",
    "time_seq = times/t_max\n",
    "# print('time_seq: ',time_seq)\n",
    "print('Data.shape: ',Data.shape)\n",
    "print('times.shape: ',times.shape)\n",
    "# print('Data_test.shape: ',Data_test.shape)\n",
    "\n",
    "# scaling_factor = to_np(Data).max()\n",
    "# args.scaling_factor = np.quantile(Data.flatten(), 0.99) #Data.max()\n",
    "print('scaling_factor: ',args.scaling_factor)\n",
    "# if args.data_dim=='orig':\n",
    "#     Data = args.scaling_factor.fit_transform(Data)\n",
    "    # Data = torch.Tensor(Data).double()\n",
    "# else: \n",
    "#     Data = Data/args.scaling_factor\n",
    "# Data = torch.Tensor(Data.values).double()\n",
    "Data = torch.Tensor(Data).double()\n",
    "# Data_test = Data_test/args.scaling_factor\n",
    "\n",
    "# Data = torch.from_numpy(Data).to(args.device)\n",
    "# if args.subtract_mean_per_dim:\n",
    "#     Data = Data-Data.mean(axis=0)\n",
    "\n",
    "# Data_test = torch.Tensor(Data_test).double()\n",
    "\n",
    "#Original Dataset setup \n",
    "if args.one_curve_per_frame: \n",
    "    Data_splitting_indices = Train_val_split3(np.copy(index_np),args.validation_split, args.segment_len,args.segment_window_factor) #Just the first 100 are used for training and validation\n",
    "else:\n",
    "    Data_splitting_indices = Train_val_split2(np.copy(index_np),args.validation_split, args.segment_len,args.segment_window_factor) #Just the first 100 are used for training and validation\n",
    "# Train_Data_indices = Data_splitting_indices.train_IDs()\n",
    "# Val_Data_indices = Data_splitting_indices.val_IDs()\n",
    "\n",
    "# First half for training and second half for validation\n",
    "Train_Data_indices = np.arange(len(Data_splitting_indices.train_IDs()))\n",
    "Val_Data_indices = np.arange(len(Data_splitting_indices.val_IDs()))+len(Data_splitting_indices.train_IDs())\n",
    "\n",
    "# frames_to_drop = np.random.randint(args.randomly_drop_n_last_frames+1, size=len(Data))\n",
    "if args.randomly_drop_n_last_frames is not None:\n",
    "    frames_to_drop = np.random.randint(args.randomly_drop_n_last_frames, size=len(Val_Data_indices)+len(Train_Data_indices))\n",
    "elif args.drop_n_last_frames is not None:\n",
    "    frames_to_drop = np.ones(len(Val_Data_indices)+len(Train_Data_indices),dtype=np.int8) * args.drop_n_last_frames\n",
    "elif args.num_points_for_c is not None:\n",
    "    args.drop_n_last_frames = args.segment_len-args.num_points_for_c\n",
    "    frames_to_drop = np.ones(len(Val_Data_indices)+len(Train_Data_indices),dtype=np.int8) * args.drop_n_last_frames\n",
    "    \n",
    "print('\\nlen(Train_Data_indices): ',len(Train_Data_indices))\n",
    "print('Train_Data_indices: ',Train_Data_indices)\n",
    "print('\\nlen(Val_Data_indices): ',len(Val_Data_indices))\n",
    "print('Val_Data_indices: ',Val_Data_indices)\n",
    "print('frames_to_drop [for train]: ',frames_to_drop[Train_Data_indices])\n",
    "print('frames_to_drop [for val]: ',frames_to_drop[Val_Data_indices])\n",
    "# # #Define frames to drop\n",
    "# if args.randomly_drop_n_last_frames is not None:\n",
    "#     args.randomly_drop_n_last_frames = np.random.randint(args.randomly_drop_n_last_frames, size=len(Val_Data_indices)+len(Train_Data_indices))\n",
    "# print('args.randomly_drop_n_last_frames; ',args.randomly_drop_n_last_frames)\n",
    "            \n",
    "Dataset = Dynamics_Dataset2(Data,times,args.segment_len,args.segment_window_factor, frames_to_drop)\n",
    "\n",
    "# times_np_test = np.linspace(t_min, t_max, num=Data_test.shape[0])\n",
    "# times_np_test = np.linspace(t_min, t_max, num=Data_test.shape[0])\n",
    "# times_np_test = np.hstack([times_np_test[:, None]])\n",
    "# times_test = torch.from_numpy(times_np_test[:, :, None])#.to(args.device)\n",
    "# times_test = times_test.flatten()\n",
    "# Dataset_all = Test_Dynamics_Dataset(Data_test,times_test)\n",
    "\n",
    "# For the sampler\n",
    "train_sampler = SubsetRandomSampler(Train_Data_indices)\n",
    "valid_sampler = SubsetRandomSampler(Val_Data_indices)\n",
    "    \n",
    "# loader_val = torch.utils.data.DataLoader(Dataset, batch_size = args.batch_size)\n",
    "\n",
    "dataloaders = {'train': torch.utils.data.DataLoader(Dataset, sampler=train_sampler, batch_size = args.batch_size,  \n",
    "                                                    num_workers=args.num_workers, drop_last=False),\n",
    "               'val': torch.utils.data.DataLoader(Dataset, sampler=valid_sampler, batch_size = args.batch_size, \n",
    "                                                   num_workers=args.num_workers, drop_last=False),\n",
    "               # 'test': torch.utils.data.DataLoader(Dataset_all, batch_size = len(times_test),  num_workers=args.num_workers)\n",
    "              }\n",
    "# print('Data: ', Data)\n",
    "\n",
    "# after creating the dataloader, move the Data back to GPU\n",
    "Data = Data.to(args.device)\n",
    "\n",
    "obs_, ts_, ids_, frames_to_drop_ = next(iter(dataloaders['train']))\n",
    "print('obs_.shape: ',obs_.shape)\n",
    "print('ts_.shape: ',ts_.shape)\n",
    "print('ids_.shape: ',ids_.shape)\n",
    "print('frames_to_drop_.shape: ',frames_to_drop_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f8792b-4fe5-4336-af4e-f378f4c57706",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_mode = args.exp_mode#'Fredholm'\n",
    "#Fredholm mode\n",
    "mask = None\n",
    "\n",
    "#Volterra mode\n",
    "if exp_mode == 'Volterra':\n",
    "    masking_map =  masking_function(lambda x: 0.,lambda x: x,n_batch=1)\n",
    "    mask_times = times\n",
    "    mask = masking_map.create_mask(mask_times).to(args.device)\n",
    "    \n",
    "Full_experiment_AttentionalIE_GeneratedFMRI(model,Data, dataloaders, times, index_np, mask, None, args, extrapolation_points=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b900a1ec-4885-4aac-9e17-7905ebc2f25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97259e57-100a-457e-ae0a-b939b6634ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
