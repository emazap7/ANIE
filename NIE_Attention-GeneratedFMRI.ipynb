{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adcd9c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/dijk/ahf38/conda_envs/neural_ide3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#General libraries\n",
    "import os, argparse\n",
    "import pickle\n",
    "#from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "#Torch libraries\n",
    "import torch \n",
    "\n",
    "#Custom libraries\n",
    "#from load_datasets import load_dataset, create_dataloaders\n",
    "from IE_source.utils import Train_val_split2, Train_val_split3, Dynamics_Dataset2, Test_Dynamics_Dataset\n",
    "from IE_source.utils import fix_random_seeds,to_np, count_parameters\n",
    "#from source.ide_func import NNIDEF, NeuralIDE\n",
    "#from IE_source.solver import IESolver_monoidal\n",
    "import IE_source.kernels as kernels\n",
    "from IE_source.experiments import Full_experiment_AttentionalIE_GeneratedFMRI\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from IE_source.kernels import model_blocks\n",
    "\n",
    "from IE_source.Attentional_IE_solver import masking_function\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"\n",
    "    \n",
    "\n",
    "parser = argparse.ArgumentParser(description='Neural IE')\n",
    "parser.add_argument('-root_path', metavar='DIR', default='/home/ahf38/project/ANIE/',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('-dataset-name', default='stl10',\n",
    "                    help='dataset name', choices=['acrobot_dataset'])\n",
    "parser.add_argument('-j', '--num_workers', default=0, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 32)')\n",
    "parser.add_argument('--epochs', default=3000, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('-b', '--batch_size', default=20, type=int,\n",
    "                    metavar='N',\n",
    "                    help='mini-batch size (default: 256), this is the total '\n",
    "                         'batch size of all GPUs on the current node when '\n",
    "                         'using Data Parallel or Distributed Data Parallel')\n",
    "parser.add_argument('--lr', '--learning-rate', default=1e-4, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "parser.add_argument('--seed', default=None, type=int,\n",
    "                    help='seed for initializing training. ')\n",
    "parser.add_argument('--disable-cuda', action='store_true',\n",
    "                    help='Disable CUDA')\n",
    "parser.add_argument('--fp16-precision', action='store_true',\n",
    "                    help='Whether or not to use 16-bit precision GPU training.')\n",
    "\n",
    "parser.add_argument('--out_dim', default=128, type=int,\n",
    "                    help='feature dimension (default: 128)')\n",
    "parser.add_argument('--log-every-n-steps', default=100, type=int,\n",
    "                    help='Log every n steps')\n",
    "parser.add_argument('--temperature', default=0.07, type=float,\n",
    "                    help='softmax temperature (default: 0.07)')\n",
    "parser.add_argument('--n-views', default=2, type=int, metavar='N',\n",
    "                    help='Number of views for contrastive learning training.')\n",
    "parser.add_argument('--gpu-index', default=0, type=int, help='Gpu index.')\n",
    "parser.add_argument('--model', default='simclr', choices=['simclr','lipschitz_simclr','vae','gan'], \n",
    "                    help='Models to be used')\n",
    "parser.add_argument('--mode', default='train', choices=['train','evaluate'], \n",
    "                    help='Set to ''evaluate'' if inference is desired')\n",
    "parser.add_argument('--validation_split', default=0.25,type=float, \n",
    "                    help='Fraction of the samples that will be used for validation')\n",
    "parser.add_argument('--resume_from_checkpoint', default=None, \n",
    "                    help='Give string to run number. Ex: \"run12\"')\n",
    "parser.add_argument('--plot_freq', default=1, type=int,help='')\n",
    "parser.add_argument('--experiment_name', default=None,help='')\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c42f81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model='nie'\n",
    "args.mode='train'\n",
    "#args.mode = 'evaluate'\n",
    "args.dataset_name = 'integral_equations'\n",
    "args.seed = 1\n",
    "fix_random_seeds(args.seed)\n",
    "args.batch_size = 32\n",
    "args.log_per_minibatch=True\n",
    "args.num_minibatches=5\n",
    "args.experiment_name = ''\n",
    "args.plot_freq = 1\n",
    "args.device = device\n",
    "args.num_dim_plot = 20\n",
    "args.lr = 1e-3\n",
    "args.min_lr=1e-6\n",
    "args.T_max = 50\n",
    "args.plat_patience = 10\n",
    "args.factor = 0.5\n",
    "args.warm_up=15\n",
    "args.exp_mode = 'Fredholm' #'Fredholm'\n",
    "# args.temperature=0.001\n",
    "#args.lr_scheduler = 'ReduceLROnPlateau'\n",
    "args.experiment_name = 'GeneratedFMRI' #'Data_RandProj_20pcs_150frames', Data_20pcs_150frames\n",
    "args.data_dim = 'orig' #'Data_2D', 'Data_10D', 'Data_50D', 'Data_orig'\n",
    "args.lr_scheduler = 'CosineAnnealingLR' #'ReduceLROnPlateau'\n",
    "# args.resume_from_checkpoint = 'run20'\n",
    "args.perturbation_to_obs0=None\n",
    "args.downsample_orig_data=10 # Factor by which we will downsampled the original data \n",
    "args.use_first_n_frames = 5000\n",
    "# args.subtract_mean_per_dim = True\n",
    "args.segment_len=20\n",
    "args.validation_split=0.5\n",
    "args.segment_window_factor = 0\n",
    "args.randomly_drop_n_last_frames = None\n",
    "args.drop_n_last_frames=None\n",
    "args.perturbation_to_obs = False\n",
    "args.perturbation_to_t = False\n",
    "args.random_sample_n_points=None\n",
    "# args.perturbation_to_obs_factor = 10000 #This scales the std of the data, like (std_data)/factor. The previous test used factor=20\n",
    "\n",
    "\n",
    "args.kernel_split = True\n",
    "args.free_func_nn = False\n",
    "args.kernel_type_nn = True\n",
    "args.G_NN = True\n",
    "args.num_internal_points = 100 ##For non-attentional model\n",
    "args.plot_F_func = False\n",
    "args.f_nn = False\n",
    "args.max_iterations=3\n",
    "args.sampling_points=100 ##For attentional model\n",
    "args.time_points=100  ##Number of dummy points when support_tensors is True\n",
    "\n",
    "# These options only work with batch_size=1\n",
    "args.support_tensors=False # Dummy points for training\n",
    "args.support_test = False # Plotting for inference\n",
    "args.combine_points=False\n",
    "args.output_support_tensors = False # Set it to false to return just the real coordinates\n",
    "args.use_support = False\n",
    "\n",
    "args.integral_c='cte_2nd_half' #to pass c as a function fitted on few real points defined by 'num_points_for_c' or None \n",
    "args.num_points_for_c=1\n",
    "args.c_scaling_factor=1\n",
    "\n",
    "args.compute_loss_on_unseen_points = False\n",
    "args.smoothing_factor=0.5\n",
    "args.one_curve_per_frame=True\n",
    "\n",
    "args.dim = 80\n",
    "args.dim_emb=128\n",
    "args.n_head=4\n",
    "args.n_blocks=3\n",
    "args.n_ff=128\n",
    "args.attention_type='galerkin'\n",
    "args.final_block=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1365cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = 1 #frames.shape[0]\n",
    "t_min = 0\n",
    "n_points = 100 #This is for the data\n",
    "\n",
    "index_np = np.arange(0, n_points, 1, dtype=int)\n",
    "index_np = np.hstack(index_np[:, None])\n",
    "times_np = np.linspace(t_min, t_max, num=n_points)\n",
    "times_np = np.hstack([times_np[:, None]])\n",
    "# print('times_np: ',times_np)\n",
    "\n",
    "###########################################################\n",
    "times = torch.from_numpy(times_np[:, :, None]).to(device)\n",
    "times = times.flatten().float()\n",
    "# print('times :',times)\n",
    "###########################################################\n",
    "args.time_interval=t_min, t_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "087195f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  321233\n"
     ]
    }
   ],
   "source": [
    "model = model_blocks(args.dim,\n",
    "                     args.dim_emb,\n",
    "                     args.n_head,\n",
    "                     args.n_blocks,\n",
    "                     args.n_ff,\n",
    "                     args.attention_type,\n",
    "                     args.final_block,\n",
    "                     dropout=0.1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    \n",
    "print('Total: ',count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "639afc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  ./datasets/GeneratedFMRI.p\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/dijk/ahf38/conda_envs/neural_ide3/lib/python3.10/site-packages/sklearn/base.py:288: UserWarning: Trying to unpickle estimator PCA from version 1.0.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Data_2D', 'Data_10D', 'Data_50D', 'Data_orig', 'pca_proj_2D', 'pca_proj_10D', 'pca_proj_50D', 'time', 'model'])\n",
      "[imported] Data.shape:  (100000, 80)\n",
      "Data.shape:  (10000, 80)\n",
      "scaling_factor:  5.3666900239388795\n",
      "Data.shape:  (5000, 80)\n",
      "times.shape:  torch.Size([20])\n",
      "scaling_factor:  5.3666900239388795\n",
      "bins:  [   0    1    2 ... 4976 4977 4978]\n",
      "IDs: [4357  248 4885 ...  905 3980  235]\n",
      "\n",
      "len(Train_Data_indices):  2489\n",
      "Train_Data_indices:  [   0    1    2 ... 2486 2487 2488]\n",
      "\n",
      "len(Val_Data_indices):  2490\n",
      "Val_Data_indices:  [2489 2490 2491 ... 4976 4977 4978]\n",
      "frames_to_drop [for train]:  [19 19 19 ... 19 19 19]\n",
      "frames_to_drop [for val]:  [19 19 19 ... 19 19 19]\n",
      "obs_.shape:  torch.Size([32, 20, 80])\n",
      "ts_.shape:  torch.Size([32, 20])\n",
      "ids_.shape:  torch.Size([32, 20])\n",
      "frames_to_drop_.shape:  torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Load data \n",
    "# Data = pickle.load(open( \"30_IE_Spirals_noise.pkl\", \"rb\" )) # Emanuele's data \n",
    "print('Loading ',os.path.join(\"./datasets\",args.experiment_name + \".p\"))\n",
    "Data_dict = pickle.load(open(os.path.join(\"./datasets\",args.experiment_name + \".p\"), \"rb\" )) #This data was saved in GPU. So transform it to CPU first\n",
    "print(Data_dict.keys())\n",
    "Data = Data_dict['Data_'+args.data_dim]#[:50,:]\n",
    "print('[imported] Data.shape: ',Data.shape)\n",
    "\n",
    "if args.data_dim=='orig':\n",
    "    # from sklearn.preprocessing import StandardScaler\n",
    "    # args.scaling_factor = StandardScaler()\n",
    "     # from sklearn.preprocessing import StandardScaler\n",
    "    # args.scaling_factor = StandardScaler()\n",
    "    import matplotlib.pyplot as plt\n",
    "    Data = np.log(Data.values)\n",
    "    args.scaling_factor = np.quantile(np.abs(Data),0.90)\n",
    "    Data = (Data-np.mean(Data))/args.scaling_factor\n",
    "    Data = Data[::args.downsample_orig_data,:]\n",
    "else: \n",
    "    args.scaling_factor = np.quantile(np.abs(Data),0.90)\n",
    "\n",
    "print('Data.shape: ',Data.shape)\n",
    "args.std_noise = np.mean(np.std(Data,axis=1))/args.perturbation_to_obs_factor if args.perturbation_to_obs else 0\n",
    "print('scaling_factor: ',args.scaling_factor)\n",
    "\n",
    "\n",
    "# args.range_imshow = np.array([np.quantile(Data.flatten(), 0.4), np.quantile(Data.flatten(), 0.55)])#np.array([-0.25,0.05]) #\n",
    "# print('args.range_imshow: ',args.range_imshow)\n",
    "# args.fitted_pca = Data_dict['pca']\n",
    "# Data = to_np(Data[:,:4]) #This might be necessary in some cases. Not sure why some of these variables were saved as CUDA.\n",
    "\n",
    "train_val = 20000 # Number of frames for train and validation. The remaining will be for test\n",
    "n_steps = 3000 #number of iterations for training. default=3k epochs\n",
    "# segment_len = args.segment_len\n",
    "\n",
    "# Data_test = Data[train_val:,:]\n",
    "Data = Data[:args.use_first_n_frames,:] #Data[:train_val,:]\n",
    "\n",
    "n_points = Data.shape[0]\n",
    "extrapolation_points = Data.shape[0]\n",
    "\n",
    "t_max = 1 #frames.shape[0]\n",
    "t_min = 0\n",
    "\n",
    "index_np = np.arange(0, n_points, 1, dtype=int)\n",
    "index_np = np.hstack(index_np[:, None])\n",
    "# times_np = np.linspace(t_min, t_max, num=n_points) #Original\n",
    "times_np = np.linspace(t_min, t_max, num=args.segment_len)\n",
    "times_np = np.hstack([times_np[:, None]])\n",
    "# print('times_np: ',times_np)\n",
    "\n",
    "###########################################################\n",
    "times = torch.from_numpy(times_np[:, :, None])#.to(args.device)\n",
    "times = times.flatten()\n",
    "\n",
    "\n",
    "time_seq = times/t_max\n",
    "# print('time_seq: ',time_seq)\n",
    "print('Data.shape: ',Data.shape)\n",
    "print('times.shape: ',times.shape)\n",
    "# print('Data_test.shape: ',Data_test.shape)\n",
    "\n",
    "# scaling_factor = to_np(Data).max()\n",
    "# args.scaling_factor = np.quantile(Data.flatten(), 0.99) #Data.max()\n",
    "print('scaling_factor: ',args.scaling_factor)\n",
    "# if args.data_dim=='orig':\n",
    "#     Data = args.scaling_factor.fit_transform(Data)\n",
    "    # Data = torch.Tensor(Data).double()\n",
    "# else: \n",
    "#     Data = Data/args.scaling_factor\n",
    "# Data = torch.Tensor(Data.values).double()\n",
    "Data = torch.Tensor(Data).double()\n",
    "# Data_test = Data_test/args.scaling_factor\n",
    "\n",
    "# Data = torch.from_numpy(Data).to(args.device)\n",
    "# if args.subtract_mean_per_dim:\n",
    "#     Data = Data-Data.mean(axis=0)\n",
    "\n",
    "# Data_test = torch.Tensor(Data_test).double()\n",
    "\n",
    "#Original Dataset setup \n",
    "if args.one_curve_per_frame: \n",
    "    Data_splitting_indices = Train_val_split3(np.copy(index_np),args.validation_split, args.segment_len,args.segment_window_factor) #Just the first 100 are used for training and validation\n",
    "else:\n",
    "    Data_splitting_indices = Train_val_split2(np.copy(index_np),args.validation_split, args.segment_len,args.segment_window_factor) #Just the first 100 are used for training and validation\n",
    "# Train_Data_indices = Data_splitting_indices.train_IDs()\n",
    "# Val_Data_indices = Data_splitting_indices.val_IDs()\n",
    "\n",
    "# First half for training and second half for validation\n",
    "Train_Data_indices = np.arange(len(Data_splitting_indices.train_IDs()))\n",
    "Val_Data_indices = np.arange(len(Data_splitting_indices.val_IDs()))+len(Data_splitting_indices.train_IDs())\n",
    "\n",
    "# frames_to_drop = np.random.randint(args.randomly_drop_n_last_frames+1, size=len(Data))\n",
    "if args.randomly_drop_n_last_frames is not None:\n",
    "    frames_to_drop = np.random.randint(args.randomly_drop_n_last_frames, size=len(Val_Data_indices)+len(Train_Data_indices))\n",
    "elif args.drop_n_last_frames is not None:\n",
    "    frames_to_drop = np.ones(len(Val_Data_indices)+len(Train_Data_indices),dtype=np.int8) * args.drop_n_last_frames\n",
    "elif args.num_points_for_c is not None:\n",
    "    args.drop_n_last_frames = args.segment_len-args.num_points_for_c\n",
    "    frames_to_drop = np.ones(len(Val_Data_indices)+len(Train_Data_indices),dtype=np.int8) * args.drop_n_last_frames\n",
    "    \n",
    "print('\\nlen(Train_Data_indices): ',len(Train_Data_indices))\n",
    "print('Train_Data_indices: ',Train_Data_indices)\n",
    "print('\\nlen(Val_Data_indices): ',len(Val_Data_indices))\n",
    "print('Val_Data_indices: ',Val_Data_indices)\n",
    "print('frames_to_drop [for train]: ',frames_to_drop[Train_Data_indices])\n",
    "print('frames_to_drop [for val]: ',frames_to_drop[Val_Data_indices])\n",
    "# # #Define frames to drop\n",
    "# if args.randomly_drop_n_last_frames is not None:\n",
    "#     args.randomly_drop_n_last_frames = np.random.randint(args.randomly_drop_n_last_frames, size=len(Val_Data_indices)+len(Train_Data_indices))\n",
    "# print('args.randomly_drop_n_last_frames; ',args.randomly_drop_n_last_frames)\n",
    "            \n",
    "Dataset = Dynamics_Dataset2(Data,times,args.segment_len,args.segment_window_factor, frames_to_drop)\n",
    "\n",
    "# times_np_test = np.linspace(t_min, t_max, num=Data_test.shape[0])\n",
    "# times_np_test = np.linspace(t_min, t_max, num=Data_test.shape[0])\n",
    "# times_np_test = np.hstack([times_np_test[:, None]])\n",
    "# times_test = torch.from_numpy(times_np_test[:, :, None])#.to(args.device)\n",
    "# times_test = times_test.flatten()\n",
    "# Dataset_all = Test_Dynamics_Dataset(Data_test,times_test)\n",
    "\n",
    "# For the sampler\n",
    "train_sampler = SubsetRandomSampler(Train_Data_indices)\n",
    "valid_sampler = SubsetRandomSampler(Val_Data_indices)\n",
    "    \n",
    "# loader_val = torch.utils.data.DataLoader(Dataset, batch_size = args.batch_size)\n",
    "\n",
    "dataloaders = {'train': torch.utils.data.DataLoader(Dataset, sampler=train_sampler, batch_size = args.batch_size,  \n",
    "                                                    num_workers=args.num_workers, drop_last=False),\n",
    "               'val': torch.utils.data.DataLoader(Dataset, sampler=valid_sampler, batch_size = args.batch_size, \n",
    "                                                   num_workers=args.num_workers, drop_last=False),\n",
    "               # 'test': torch.utils.data.DataLoader(Dataset_all, batch_size = len(times_test),  num_workers=args.num_workers)\n",
    "              }\n",
    "# print('Data: ', Data)\n",
    "\n",
    "# after creating the dataloader, move the Data back to GPU\n",
    "Data = Data.to(args.device)\n",
    "\n",
    "obs_, ts_, ids_, frames_to_drop_ = next(iter(dataloaders['train']))\n",
    "print('obs_.shape: ',obs_.shape)\n",
    "print('ts_.shape: ',ts_.shape)\n",
    "print('ids_.shape: ',ids_.shape)\n",
    "print('frames_to_drop_.shape: ',frames_to_drop_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f8792b-4fe5-4336-af4e-f378f4c57706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_to_experiment:  /home/ahf38/project/ANIE/nie/GeneratedFMRI\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/78 [00:00<?, ?it/s]/gpfs/gibbs/project/dijk/ahf38/ANIE/IE_source/Attentional_IE_solver.py:294: UserWarning: Error increased on iteration 0\n",
      "  warnings.warn(\n",
      "/gpfs/gibbs/project/dijk/ahf38/ANIE/IE_source/Attentional_IE_solver.py:294: UserWarning: Error increased on iteration 1\n",
      "  warnings.warn(\n",
      "/gpfs/gibbs/project/dijk/ahf38/ANIE/IE_source/Attentional_IE_solver.py:294: UserWarning: Error increased on iteration 2\n",
      "  warnings.warn(\n",
      "  1%|▏         | 1/78 [00:03<04:34,  3.57s/it]/gpfs/gibbs/project/dijk/ahf38/ANIE/IE_source/Attentional_IE_solver.py:294: UserWarning: Error increased on iteration 2\n",
      "  warnings.warn(\n",
      "/gpfs/gibbs/project/dijk/ahf38/ANIE/IE_source/Attentional_IE_solver.py:294: UserWarning: Error increased on iteration 1\n",
      "  warnings.warn(\n",
      "/gpfs/gibbs/project/dijk/ahf38/ANIE/IE_source/Attentional_IE_solver.py:294: UserWarning: Error increased on iteration 2\n",
      "  warnings.warn(\n",
      " 32%|███▏      | 25/78 [00:04<00:03, 15.90it/s]/gpfs/gibbs/project/dijk/ahf38/ANIE/IE_source/Attentional_IE_solver.py:294: UserWarning: Error increased on iteration 1\n",
      "  warnings.warn(\n",
      "/gpfs/gibbs/project/dijk/ahf38/ANIE/IE_source/Attentional_IE_solver.py:294: UserWarning: Error increased on iteration 1\n",
      "  warnings.warn(\n",
      " 36%|███▌      | 28/78 [00:04<00:02, 17.75it/s]/gpfs/gibbs/project/dijk/ahf38/ANIE/IE_source/Attentional_IE_solver.py:294: UserWarning: Error increased on iteration 1\n",
      "  warnings.warn(\n",
      " 51%|█████▏    | 40/78 [00:05<00:01, 22.29it/s]/gpfs/gibbs/project/dijk/ahf38/ANIE/IE_source/Attentional_IE_solver.py:294: UserWarning: Error increased on iteration 2\n",
      "  warnings.warn(\n",
      "100%|██████████| 78/78 [00:06<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[plot_dim_vs_time] obs_to_print.shape:  (20, 80)\n",
      "[plot_dim_vs_time] time_to_print.shape:  (20,)\n",
      "[plot_dim_vs_time] args.num_dim_plot:  20\n",
      "[plot_dim_vs_time] dummy_times_to_print.shape:  (20,)\n",
      "[plot_dim_vs_time] z_all_to_print.shape:  (20, 80)\n",
      "[plot_dim_vs_time] obs_to_print.shape:  (20, 80)\n",
      "[plot_dim_vs_time] time_to_print.shape:  (20,)\n",
      "[plot_dim_vs_time] args.num_dim_plot:  20\n",
      "[plot_dim_vs_time] dummy_times_to_print.shape:  (20,)\n",
      "[plot_dim_vs_time] z_all_to_print.shape:  (20, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/78 [00:00<00:01, 37.77it/s]/gpfs/gibbs/project/dijk/ahf38/ANIE/IE_source/Attentional_IE_solver.py:294: UserWarning: Error increased on iteration 2\n",
      "  warnings.warn(\n",
      "100%|██████████| 78/78 [00:02<00:00, 38.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[plot_dim_vs_time] obs_to_print.shape:  (20, 80)\n",
      "[plot_dim_vs_time] time_to_print.shape:  (20,)\n",
      "[plot_dim_vs_time] args.num_dim_plot:  20\n",
      "[plot_dim_vs_time] dummy_times_to_print.shape:  (20,)\n",
      "[plot_dim_vs_time] z_all_to_print.shape:  (20, 80)\n",
      "[plot_dim_vs_time] obs_to_print.shape:  (20, 80)\n",
      "[plot_dim_vs_time] time_to_print.shape:  (20,)\n",
      "[plot_dim_vs_time] args.num_dim_plot:  20\n",
      "[plot_dim_vs_time] dummy_times_to_print.shape:  (20,)\n",
      "[plot_dim_vs_time] z_all_to_print.shape:  (20, 80)\n",
      "\n",
      "Best validation loss: 0.14125683526449564\n",
      "Saving best model for epoch: 1\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_last_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     mask_times \u001b[38;5;241m=\u001b[39m times\n\u001b[1;32m      9\u001b[0m     mask \u001b[38;5;241m=\u001b[39m masking_map\u001b[38;5;241m.\u001b[39mcreate_mask(mask_times)\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mFull_experiment_AttentionalIE_GeneratedFMRI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextrapolation_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/gibbs/project/dijk/ahf38/ANIE/IE_source/experiments.py:7183\u001b[0m, in \u001b[0;36mFull_experiment_AttentionalIE_GeneratedFMRI\u001b[0;34m(model, Data, dataloaders, time_seq, index_np, mask, times, args, extrapolation_points)\u001b[0m\n\u001b[1;32m   7181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m   7182\u001b[0m     save_best_model(path_to_save_models, all_train_loss[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], epoch, model_state, model, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 7183\u001b[0m \u001b[43msave_last_model\u001b[49m(path_to_save_models, all_train_loss[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], epoch, model_state, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   7185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_val_loss)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   7186\u001b[0m     early_stopping(all_val_loss[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_last_model' is not defined"
     ]
    }
   ],
   "source": [
    "exp_mode = args.exp_mode#'Fredholm'\n",
    "#Fredholm mode\n",
    "mask = None\n",
    "\n",
    "#Volterra mode\n",
    "if exp_mode == 'Volterra':\n",
    "    masking_map =  masking_function(lambda x: 0.,lambda x: x,n_batch=1)\n",
    "    mask_times = times\n",
    "    mask = masking_map.create_mask(mask_times).to(args.device)\n",
    "    \n",
    "Full_experiment_AttentionalIE_GeneratedFMRI(model,Data, dataloaders, times, index_np, mask, None, args, extrapolation_points=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b900a1ec-4885-4aac-9e17-7905ebc2f25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97259e57-100a-457e-ae0a-b939b6634ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
